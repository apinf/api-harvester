{"title":"Distill: An Interactive, Visual Journal for Machine Learning Research","endpoint":"Michael Nielsen","description":"\n                         The journal Distill launches today. In a nutshell, Distill is an interactive, visual journal for machine learning research.\nThe web has been around for almost 30 years. But you wouldn’t know it if you looked at most academic journals. They’re stuck in the early 1900s. PDFs are not an exciting form.\nDistill is taking the web seriously. A Distill article (at least in its ideal, aspirational form) isn’t just a paper. It’s an interactive medium that lets users – “readers” is no longer sufficient – work directly with machine learning models.\nIdeally, such articles will integrate explanation, code, data, and interactive visualizations into a single environment. In such an environment, users can explore in ways impossible with traditional static media. They can change models, try out different hypotheses, and immediately see what happens. That will let them rapidly build their understanding in ways impossible in traditional static media.\nOne day, perhaps, Distill articles will be a creative medium in their own right, a medium where it is possible to do exploratory machine learning research.\nAt launch, Distill contains expository articles on subjects such as attention in neural networks, visualizing high-dimensional data using t-SNE, and using neural nets to generate handwriting.\nThese are unusually innovative and high-quality expositions. And they point the way to what Distill articles could become.\nGoing forward, Distill will publish both original research articles and expository articles. If you’re interested in submitting, please consult the page about publishing in Distill.\nDistill is being launched with considerable support.\nChris Olah and Shan Carter from Google Brain are the founding editors, and the key people behind the overall vision and execution.\nChris and Shan have a great deal of experience in creating very high quality expository and visual materials. They’re committed to supporting authors to create high quality expositions, and visual and dynamic elements.\nSupporting Chris and Shan are the Distill Steering Committee. The members of the Steering Committee include YC Research Fellow Michael Nielsen. The full list of members is:\n\nYoshua Bengio (University of Montreal)\nMike Bostock (creator of d3)\nAmanda Cox (New York Times)\nIan Goodfellow (Google Brain)\nAndrej Karpathy (OpenAI)\nShakir Mohamed (DeepMind)\nMichael Nielsen (Y Combinator Research)\nFernanda Viegas (Google Brain)\n\nDistill is integrated in standard ways into the traditional scholarly publishing system (ISSN, CrossRef, and so on). Distill articles will appear in Google Scholar, which will help authors receive academic credit. And Distill articles will be licensed under Creative Commons Attribution licenses.\nThere’s much more that could be said. I haven’t touched on many of the ideas about Distill that most excite me – especially connections to intelligence augmentation, and to humane AI. But that’s enough for one post. Please take a look!\n                                             "}